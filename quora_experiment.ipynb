{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data_path = os.path.join(\"data\",\"en_quora_questions.csv\")\n",
    "ar_data_path = os.path.join(\"data\", \"arabic_categorization_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(en_data_path, usecols=[\"question_text\"])\n",
    "df_ar = pd.read_csv(ar_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810887</th>\n",
       "      <td>What do you think of the situation of base bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873486</th>\n",
       "      <td>How long would it take to reach $1000 per day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531286</th>\n",
       "      <td>Why can't I post in any groups on Google+?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131262</th>\n",
       "      <td>What are some important facts about PVA glue?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280119</th>\n",
       "      <td>What do you think of the movie \"212\"?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question_text\n",
       "810887   What do you think of the situation of base bei...\n",
       "873486   How long would it take to reach $1000 per day ...\n",
       "531286          Why can't I post in any groups on Google+?\n",
       "1131262      What are some important facts about PVA glue?\n",
       "1280119              What do you think of the movie \"212\"?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer(\n",
       "    (auto_model): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50267, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Pooling()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder_en = SentenceTransformer('distilroberta-base-msmarco-v1')\n",
    "embedder_en.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sentence = '[QRY] ' + df.sample()[\"question_text\"].values[0]\n",
    "doc_sentence = '[QRY] ' + df.sample()[\"question_text\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sentence = '[QRY] ' + \"Hello, my name is Erez\"\n",
    "doc_sentence = '[DOC] ' + \"Hey there, you can call me erez\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"quora_questions_embeddiong.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(res, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397f40b43b824a5483b12ecc98ec901c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=40817.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_list = list(df[\"question_text\"].values)\n",
    "\n",
    "res = model.encode(text_list, show_progress_bar=True, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa8528f62414c489ce8089f7b220619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=324.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_ar_list = list(df_ar[\"text\"].values)\n",
    "res = multilingual_model.encode(text_ar_list, show_progress_bar=True, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"arabic_embeddiong.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(res, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating food. (Score: 0.2719)\n",
      "A man is eating a piece of bread. (Score: 0.2637)\n",
      "A cheetah is running behind its prey. (Score: 0.0598)\n",
      "A woman is playing violin. (Score: 0.0484)\n",
      "A man is riding a horse. (Score: 0.0248)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.4076)\n",
      "A cheetah is running behind its prey. (Score: 0.2005)\n",
      "A woman is playing violin. (Score: 0.0949)\n",
      "A man is eating a piece of bread. (Score: 0.0645)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.0597)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.4987)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1458)\n",
      "A man is eating a piece of bread. (Score: 0.1259)\n",
      "Two men pushed carts through the woods. (Score: 0.1054)\n",
      "A monkey is playing drums. (Score: 0.0812)\n"
     ]
    }
   ],
   "source": [
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = multilingual_model.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use torch.topk to find the highest 5 scores\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: %.4f)\" % (score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer(\n",
       "    (auto_model): XLMRobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Pooling()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilingual_model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "multilingual_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = pd.read_csv(ar_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sentence = '[QRY] ' + df_ar.sample()[\"text\"].values[0].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[QRY] إصطحب السيد جلال تقية رئيس القائمة المترشحة إلى إنتخابات المكتب الجامعي لكرة القدم عدل تنفيذ إلى مقر الجامعة التونسية لكرة القدم للمطالبة بالحصول على عدد من الوثائق التي تهم سير العملية الإنتخابية المبرمجة يوم الجمعة 18 مارس 2016 و بعض الملفات التي تخص بعد الاعضاء المنتمين إلى قائمة منافسه السيد وديع الجريئ و بالتحديد محمد السلامي و محمد الحبيب مقداد .و كان تقية قد أكد صباح اليوم في تصريح لجوهرة أف أم \\xa0أن الكتابة العامة للجامعة قد رفضت تمكينه من هذه الوثائق و الملفات .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.40024930e-01, -1.81787014e-01,  8.53352696e-02,  3.98172915e-01,\n",
       "       -2.46809661e-01,  4.18859161e-02, -4.75796819e-01, -3.56774814e-02,\n",
       "        1.67223662e-01, -3.69141102e-01,  4.31366205e-01, -4.10246290e-02,\n",
       "        1.49529949e-01,  1.09131873e-01, -7.16367364e-02, -3.92588943e-01,\n",
       "       -9.71718058e-02,  3.19534898e-01, -1.35897510e-02, -4.37093265e-02,\n",
       "       -3.57435882e-01,  3.99631083e-01, -4.50010568e-01,  2.64161557e-01,\n",
       "       -1.56988800e-01, -1.26945764e-01, -4.82577264e-01,  1.62034109e-01,\n",
       "        2.50894248e-01, -5.55638552e-01, -7.05618858e-02, -7.15702355e-01,\n",
       "       -1.03811644e-01,  1.91359177e-01, -1.05061546e-01, -4.81622696e-01,\n",
       "       -3.88598442e-02, -1.28492862e-01,  3.35470349e-01,  1.19281225e-01,\n",
       "       -2.48370051e-01, -2.28093252e-01,  2.80115366e-01,  2.95431644e-01,\n",
       "        9.24448520e-02,  5.61857633e-02,  1.09746970e-01,  3.85281324e-01,\n",
       "       -3.02449256e-01, -5.23070395e-02, -3.19032744e-02, -6.73420131e-02,\n",
       "        4.82475609e-02,  1.86615735e-01, -7.21558742e-03, -3.66476148e-01,\n",
       "        1.41678959e-01, -3.02822024e-01,  1.55528903e-01,  1.08693406e-01,\n",
       "       -1.01193815e-01, -1.71419606e-01,  3.12673934e-02,  6.93173349e-01,\n",
       "       -5.78183159e-02,  5.07810675e-02, -2.68644542e-01, -3.85827720e-02,\n",
       "        2.74267346e-01, -1.13596432e-01,  8.88244212e-02, -2.60497689e-01,\n",
       "        9.96584743e-02,  4.35882434e-02,  2.86772251e-01,  1.76098138e-01,\n",
       "       -1.82112500e-01,  6.92333654e-02, -2.08707005e-01, -2.67309956e-02,\n",
       "       -4.58386540e-02,  1.32711157e-01, -5.16813099e-01, -6.60862178e-02,\n",
       "       -5.08501470e-01, -1.74276158e-01, -5.01456521e-02, -5.55451930e-01,\n",
       "        9.94974524e-02, -2.44463123e-02,  6.37487650e-01,  2.81745374e-01,\n",
       "       -1.47653371e-01,  3.04088771e-01,  1.33402795e-01, -4.07192051e-01,\n",
       "       -1.51684374e-01, -2.00554445e-01,  2.29914859e-02, -4.59899008e-01,\n",
       "        5.61140418e-01, -1.17856964e-01,  4.11380142e-01,  8.38537440e-02,\n",
       "       -1.31565198e-01, -2.65421540e-01,  5.85714169e-02, -1.24414489e-01,\n",
       "       -1.61981985e-01, -1.69440508e-02, -1.75867200e-01, -7.84561113e-02,\n",
       "        5.04568636e-01,  1.40065014e-01, -2.92593688e-01,  5.86196423e-01,\n",
       "       -2.54045457e-01,  4.48531583e-02, -4.43192869e-01, -2.22398639e-01,\n",
       "        2.58245498e-01,  3.81498665e-01, -3.65167171e-01,  5.98560274e-01,\n",
       "       -3.22285235e-01,  7.51611665e-02, -3.73807177e-02, -5.87839223e-02,\n",
       "        1.50274143e-01, -1.46502584e-01,  5.32715656e-02, -6.86093152e-01,\n",
       "       -7.25006834e-02, -1.09700829e-01, -7.62634575e-02, -3.75152797e-01,\n",
       "       -4.07880038e-01,  1.09061778e-01, -8.74376670e-02,  2.18543615e-02,\n",
       "       -4.02369872e-02,  5.33798099e-01, -1.57085344e-01, -1.22055039e-02,\n",
       "       -8.18337500e-01,  5.52138239e-02, -4.51387167e-02, -6.63347170e-02,\n",
       "        5.44264540e-02,  1.83792878e-02,  7.62896240e-02,  1.61790401e-01,\n",
       "        3.68205190e-01, -1.99510306e-01,  1.33655474e-01,  2.08621278e-01,\n",
       "        2.52992995e-02,  1.73995510e-01, -4.25136268e-01,  5.21834075e-01,\n",
       "        1.14410736e-01,  1.50574163e-01,  7.50396848e-02, -3.93472105e-01,\n",
       "       -2.60437936e-01,  2.06613936e-03,  1.14811540e-01,  4.78968441e-01,\n",
       "        2.29338169e-01,  7.10599601e-01, -1.90583467e-01,  5.82122654e-02,\n",
       "        3.40721548e-01,  1.09160524e-02, -2.23584920e-01,  5.73062934e-02,\n",
       "        2.36708835e-01,  4.05936278e-02,  2.31738478e-01,  2.38865018e-01,\n",
       "       -9.72068459e-02, -2.75285900e-01,  5.31951152e-02,  1.51342928e-01,\n",
       "        2.69258708e-01,  9.96050760e-02, -8.72790366e-02,  4.08322364e-01,\n",
       "        3.29277217e-01, -4.39427853e-01,  6.34695590e-02,  4.33185965e-01,\n",
       "        1.58052191e-01, -3.72202337e-01,  2.27767095e-01,  2.06516430e-01,\n",
       "       -1.55956060e-01, -2.71426201e-01,  4.67099190e-01,  2.96312245e-03,\n",
       "       -9.84042361e-02,  1.31445438e-01, -1.67456761e-01,  1.11444797e-02,\n",
       "        2.05607489e-01, -4.33238372e-02,  5.80483615e-01,  3.11195366e-02,\n",
       "        8.49607401e-03, -1.69100761e-01, -3.32984030e-01,  3.03328007e-01,\n",
       "       -4.08395201e-01,  8.72864649e-02, -1.56155482e-01, -2.38315985e-01,\n",
       "       -3.31672072e-01,  5.80217659e-01, -4.70713936e-02,  3.52502912e-02,\n",
       "        1.11948960e-01,  1.51480034e-01, -1.70626432e-01, -1.83347568e-01,\n",
       "        4.04112607e-01,  5.75420916e-01, -1.83467358e-01, -1.31239653e-01,\n",
       "        5.60953259e-01, -2.75619626e-01, -1.00175641e-01, -2.82884832e-03,\n",
       "       -2.28206724e-01, -1.38839647e-01, -1.11905210e-01, -1.78797752e-01,\n",
       "       -7.05542490e-02,  9.18501094e-02, -5.01699699e-03, -1.36927798e-01,\n",
       "        7.20743895e-01, -1.22356765e-01,  5.99604137e-02, -1.97840840e-01,\n",
       "        4.49847966e-01,  5.93856096e-01, -4.62109819e-02,  1.31714970e-01,\n",
       "       -8.27396438e-02,  2.74161667e-01, -2.33884916e-01,  3.05112526e-02,\n",
       "        9.54226479e-02,  7.94804245e-02, -1.89749852e-01,  2.60853589e-01,\n",
       "        5.82597911e-01,  1.11344770e-01,  3.44119996e-01, -1.48530632e-01,\n",
       "        7.22342506e-02,  1.36390045e-01,  7.70598650e-02, -3.70381445e-01,\n",
       "        2.82565445e-01,  2.52574950e-01, -2.94846952e-01,  9.10930336e-02,\n",
       "       -2.33741570e-02, -9.94391814e-02,  2.71504559e-02,  1.24075912e-01,\n",
       "        6.35595992e-02, -6.55057430e-02, -1.06774226e-01, -6.27839491e-02,\n",
       "        7.97630474e-02, -1.42098173e-01,  1.84314877e-01,  2.99752913e-02,\n",
       "        1.73770487e-01, -2.43515149e-01,  1.63764715e-01, -3.73521239e-01,\n",
       "        3.21913809e-01,  1.73475534e-01, -2.26273060e-01,  6.44287467e-01,\n",
       "        1.12193808e-01,  1.08590119e-01, -2.95331497e-02,  1.86043650e-01,\n",
       "       -3.21994901e-01, -3.28211896e-02, -6.26159683e-02, -2.71308213e-01,\n",
       "       -5.82115278e-02, -2.77440310e-01, -2.36201301e-01, -6.73145294e-01,\n",
       "       -2.32159063e-01, -1.29361600e-01,  9.99526354e-04, -2.32846573e-01,\n",
       "       -1.56777859e-01,  1.98750813e-02,  1.20443240e-01,  3.03528309e-01,\n",
       "       -1.77223295e-01,  3.89721453e-01, -7.39537179e-02,  5.77265322e-02,\n",
       "       -2.57537700e-03,  1.77816987e-01,  2.54851311e-01, -1.92822274e-02,\n",
       "        3.27589899e-01, -2.48062953e-01,  5.02482392e-02,  1.62784338e-01,\n",
       "       -2.60967284e-01, -1.74805641e-01, -1.20821089e-01,  3.96473296e-02,\n",
       "        4.55543220e-01, -8.10125098e-02,  4.19458389e-01, -6.21217415e-02,\n",
       "        2.51171857e-01,  7.92583451e-02,  3.13016415e-01,  3.79946202e-01,\n",
       "        1.52544230e-01, -3.26739490e-01, -2.86841273e-01, -1.00468993e-02,\n",
       "        3.47811729e-02, -2.45623872e-01,  9.75445062e-02, -2.78790761e-03,\n",
       "        3.11109632e-01, -3.86571512e-03,  1.81262478e-01,  1.31231993e-01,\n",
       "       -1.54483080e-01,  2.12880760e-01, -3.03344913e-02,  4.79425415e-02,\n",
       "       -2.91257381e-01,  2.60326147e-01,  2.18044370e-01,  1.08423688e-01,\n",
       "        2.22036108e-01,  1.27639920e-01, -4.40917850e-01,  2.90941536e-01,\n",
       "        2.39802256e-01,  3.03279143e-02,  9.58510190e-02, -4.81869936e-01,\n",
       "       -7.16169700e-02,  1.89174965e-01, -1.51973516e-01,  6.82870001e-02,\n",
       "        2.03586346e-03,  1.59786437e-02, -4.48372394e-01,  2.08334789e-01,\n",
       "        1.19148485e-01,  2.91083306e-01,  1.97196871e-01, -4.06250805e-01,\n",
       "        4.49342057e-02, -3.15685421e-01,  6.53678328e-02, -2.24492133e-01,\n",
       "       -7.32213035e-02,  7.35164642e-01, -2.28484869e-02, -1.15334690e-01,\n",
       "        6.41707703e-02,  1.37569621e-01, -2.31995061e-01,  3.10248453e-02,\n",
       "       -4.42478172e-02, -2.38544613e-01, -3.79894763e-01,  1.15969153e-02,\n",
       "       -2.39071161e-01, -1.37100518e-01,  2.15059757e-01,  2.05502316e-01,\n",
       "       -8.76368135e-02,  1.03454463e-01,  1.25635847e-01,  7.33568752e-03,\n",
       "       -2.14237720e-01,  1.71628416e-01,  3.81294310e-01, -2.33363956e-01,\n",
       "        2.20449641e-01, -1.02053389e-01, -3.70365858e-01,  8.97522792e-02,\n",
       "        5.19856159e-03, -3.47694829e-02, -1.46510839e-01,  2.78389603e-01,\n",
       "       -4.15331304e-01, -1.75602570e-01, -2.68713199e-03,  8.82232115e-02,\n",
       "        1.94857176e-02, -1.30327372e-02,  1.12588868e-01,  2.38436759e-01,\n",
       "        3.30899656e-01,  1.30337566e-01, -3.85718763e-01, -2.43711501e-01,\n",
       "        2.42266450e-02, -1.03147127e-01,  3.66553366e-01, -1.90763533e-01,\n",
       "       -9.04411450e-03,  7.39467964e-02, -4.92982054e-03,  4.01624218e-02,\n",
       "       -1.08483315e-01, -1.79092556e-01,  7.15510324e-02,  1.17955446e-01,\n",
       "       -1.04965456e-01,  2.76293736e-02, -1.17247105e-01,  2.58656982e-02,\n",
       "       -5.41283451e-02,  2.31986821e-01, -2.32011989e-01,  5.35704732e-01,\n",
       "        2.72734702e-01, -1.50404721e-01, -2.35066012e-01,  1.74110100e-01,\n",
       "       -9.07883868e-02,  2.97206253e-01, -4.02018189e-01,  9.02111977e-02,\n",
       "       -3.63560855e-01, -1.36611670e-01, -2.93492079e-01,  2.53970593e-01,\n",
       "       -2.97690302e-01, -4.69183803e-01,  4.30601448e-01,  5.93788862e-01,\n",
       "        1.90527529e-01,  9.43735540e-02, -3.68329167e-01,  1.42884895e-01,\n",
       "        5.86488247e-02,  2.83587445e-02,  5.96000366e-02, -2.05856636e-02,\n",
       "        1.99511990e-01,  3.50092173e-01,  4.84936714e-01,  3.16046551e-02,\n",
       "       -2.87934035e-01, -1.76458225e-01, -3.83936316e-02,  7.46164098e-02,\n",
       "        6.40831143e-02, -5.35552986e-02, -1.72753055e-02,  3.91451657e-01,\n",
       "       -1.61864281e-01,  1.13559894e-01,  1.98932454e-01, -6.14567399e-02,\n",
       "       -2.53631055e-01, -8.11457559e-02,  1.89860910e-02,  5.87810352e-02,\n",
       "        6.85893670e-02,  8.22233483e-02, -3.26656014e-01,  2.69076645e-01,\n",
       "       -1.50961921e-01, -4.14158493e-01, -1.70867741e-01,  1.97435170e-01,\n",
       "       -2.50779927e-01,  8.98529068e-02,  1.24680686e+00,  5.38173132e-02,\n",
       "       -2.42540743e-02,  4.99021351e-01,  6.84310794e-01, -1.21585727e-02,\n",
       "       -1.54581964e-01,  1.14646919e-01,  2.96946108e-01,  2.57729679e-01,\n",
       "        9.74576846e-02, -2.78882384e-02, -5.48012853e-02, -2.81247973e-01,\n",
       "        2.46294048e-02, -2.73110449e-01, -1.30066320e-01, -5.14232635e-01,\n",
       "        9.07082204e-03, -8.78553092e-02, -1.89024910e-01, -2.40080088e-01,\n",
       "        4.70659316e-01, -6.18042126e-02,  2.27066070e-01,  4.47228462e-01,\n",
       "       -3.56481522e-01,  1.05427951e-01,  1.26012549e-01, -2.18451321e-01,\n",
       "       -1.51981682e-01,  2.30599679e-02, -3.70974869e-01,  1.42011531e-02,\n",
       "       -3.63403782e-02,  3.71206626e-02,  1.34920001e-01, -1.54000716e-02,\n",
       "       -2.55390435e-01, -5.76812811e-02, -4.55870479e-01,  4.88386095e-01,\n",
       "       -1.10707596e-01, -2.27222934e-01, -1.38004005e-01,  3.99150373e-03,\n",
       "       -4.49911565e-01, -3.22782665e-01,  2.75563538e-01, -1.60540733e-02,\n",
       "       -3.51749480e-01,  3.22704792e-01, -2.86858708e-01, -1.03051551e-01,\n",
       "        9.59545672e-02, -9.20105428e-02, -2.00419560e-01,  1.14686489e-01,\n",
       "       -3.67356390e-01,  2.84208983e-01, -1.40230715e-01, -2.61166338e-02,\n",
       "        3.63147199e-01,  8.74685794e-02, -1.15514621e-01,  2.42744744e-01,\n",
       "       -1.69644758e-01,  1.23906039e-01,  1.89889938e-01,  1.38399735e-01,\n",
       "        4.26550716e-01, -5.66806272e-02,  1.62309125e-01,  1.59453854e-01,\n",
       "        2.01479584e-01, -1.96706653e-01,  7.16330826e-01,  3.16084884e-02,\n",
       "       -1.04866505e-01,  4.54242766e-01, -3.27435344e-01, -5.53832762e-02,\n",
       "       -8.52194354e-02, -1.96348801e-01, -4.21729356e-01, -1.92093506e-01,\n",
       "       -5.67453146e-01, -4.26378846e-02,  1.12579159e-01,  9.61836651e-02,\n",
       "        2.39899412e-01,  7.45249074e-03, -1.08941354e-01, -1.20812692e-01,\n",
       "        1.06907344e+00,  1.76626414e-01,  2.53888071e-01, -5.90214022e-02,\n",
       "       -1.82832882e-01, -6.58310428e-02,  1.84254840e-01, -1.59925014e-01,\n",
       "       -3.85619968e-01, -5.65599427e-02,  1.83487087e-01, -1.01793520e-02,\n",
       "        4.16712970e-01, -5.00315905e-01,  5.05684912e-01,  2.33929962e-01,\n",
       "        4.21859562e-01, -5.88655062e-02,  9.58013758e-02, -1.41507939e-01,\n",
       "       -1.84198365e-01,  3.15725893e-01, -2.04822677e-03, -6.79615796e-01,\n",
       "        9.31001157e-02, -6.35965228e-01, -1.23676397e-02,  2.01080769e-01,\n",
       "       -9.82018933e-02, -2.94283807e-01,  9.91689637e-02, -5.63065827e-01,\n",
       "       -1.64489105e-01, -1.31213322e-01, -3.35773706e-01,  3.88367862e-01,\n",
       "       -3.75592232e-01,  1.04237139e-01,  1.52981907e-01, -6.73895404e-02,\n",
       "        1.11249559e-01,  2.03636978e-02, -1.20028138e-01,  2.25185096e-01,\n",
       "       -1.04065356e-03,  1.63007174e-02,  5.94698071e-01,  1.29842430e-01,\n",
       "        2.72711247e-01,  3.60388428e-01,  1.12805970e-01,  1.42529860e-01,\n",
       "        9.74572897e-02, -5.66341817e-01, -2.13428646e-01,  2.85322934e-01,\n",
       "        2.72009075e-01, -1.34123668e-01,  1.68289766e-01, -7.82461226e-01,\n",
       "       -2.27178246e-01, -6.12110309e-02,  6.98819533e-02, -9.45778713e-02,\n",
       "        3.20341974e-01,  2.60449618e-01,  6.66727573e-02,  3.67699005e-02,\n",
       "        1.65438086e-01,  9.90627240e-03, -2.81229645e-01,  1.18942462e-01,\n",
       "       -1.04908541e-01,  1.34485230e-01,  5.25499523e-01,  2.08607629e-01,\n",
       "        2.23152921e-01,  1.90744087e-01, -1.42696932e-01, -2.02425808e-01,\n",
       "        7.23408014e-02, -3.16850021e-02,  1.14085615e-01, -1.61953986e-01,\n",
       "        1.88113064e-01, -3.27624343e-02,  2.05237508e-01,  3.12227100e-01,\n",
       "       -1.48037657e-01, -2.02979937e-01, -6.49424940e-02,  9.64860916e-02,\n",
       "        1.90465361e-01,  4.07539785e-01,  2.01514848e-02, -2.74052680e-01,\n",
       "        5.75366020e-01,  1.92349389e-01,  2.82446623e-01,  6.74137473e-02,\n",
       "       -1.79916233e-01,  1.35088772e-01,  1.76462859e-01, -2.68131882e-01,\n",
       "        4.20918353e-02, -4.48552631e-02, -3.14513475e-01,  4.42550987e-01,\n",
       "       -5.37219830e-02,  1.07307620e-01,  2.56919749e-02,  5.59738129e-02,\n",
       "       -3.08496118e-01,  1.67053714e-01,  2.05776980e-03,  2.04418972e-01,\n",
       "       -2.23825034e-02, -2.33403549e-01,  2.28926800e-02, -1.84689701e-01,\n",
       "        2.01881900e-01, -2.31330290e-01,  2.21925732e-02, -1.48660481e-01,\n",
       "        3.18072438e-01,  2.71647573e-01, -2.50412911e-01,  1.04387388e-01,\n",
       "        7.48698264e-02, -2.85215050e-01,  1.34916246e-01, -1.34079948e-01,\n",
       "       -2.40906149e-01, -3.25342417e-02,  3.77336681e-01, -6.08942866e-01,\n",
       "       -3.64699066e-01,  2.14992445e-02,  3.81372541e-01,  3.88665497e-02,\n",
       "       -3.97067875e-01, -4.95539568e-02,  5.06770492e-01, -1.79706309e-02,\n",
       "        2.57155970e-02, -1.00527808e-01,  3.77851218e-01, -5.24702333e-02,\n",
       "        2.92989135e-01,  2.42156371e-01,  5.95533311e-01, -7.15485215e-03,\n",
       "       -7.47532248e-02, -3.78169388e-01, -4.67024058e-01, -2.69946307e-01,\n",
       "        1.45067051e-01, -7.98720270e-02,  1.72763243e-01, -2.32508019e-01,\n",
       "       -5.12244329e-02, -3.64917457e-01,  1.39714509e-01, -1.38352960e-01,\n",
       "        1.84491217e-01,  1.32335335e-01, -3.37671429e-01,  2.47107819e-01,\n",
       "        7.08450437e-01, -1.24896988e-02,  1.68782473e-01, -2.34968349e-01,\n",
       "        3.08581978e-01,  3.28568998e-03,  4.82514322e-01, -1.86153844e-01,\n",
       "        5.26615977e-01, -6.97833061e-01, -1.32789046e-01,  2.25890070e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilingual_model.encode(query_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
